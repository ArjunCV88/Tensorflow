{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1_3_StandardNN.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN8xSUeL4e3J0drDuLSd1IY"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y2XbOPtA951v",
        "colab_type": "text"
      },
      "source": [
        "1. Import tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fANYMZoP9tvB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "eb5218e5-0501-4980-c16a-7fbe142f9326"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k7U21yrD-U0e",
        "colab_type": "text"
      },
      "source": [
        "Load fashion mnist data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sM60DaIx-W2Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mnist = tf.keras.datasets.fashion_mnist"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F6x-GC-zcLD_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "a5d94797-ccd8-4146-b395-741a021edbdf"
      },
      "source": [
        "(training_images, training_labels),(test_images, test_labels) = mnist.load_data()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qu75byuadPT6",
        "colab_type": "text"
      },
      "source": [
        "Print sample training image, training label"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQKRjYLZcXjF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 758
        },
        "outputId": "9daee98b-8049-437c-ae0e-9d894b8f58ab"
      },
      "source": [
        "import numpy as np\n",
        "np.set_printoptions(linewidth = 200)\n",
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(training_images[1000])\n",
        "print(training_images[1000])\n",
        "print(training_labels[1000])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[  0   0   0   0   0   0   0   0   0   0   0  97  84  97 110 108  87  97   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0  19 255 199 183 142 161 200 213  32   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0  72 174 173 158 131 132 176 176  70   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0 142 180 163 120 180 126 139 168 122   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0 156 180 162 171 170 183 163 169 144   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0 159 177 163 174 166 173 170 163 148   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0 160 182 160 168 175 167 157 168 139   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0 143 185 161 171 184 176 160 175 131   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0 143 188 155 172 182 180 161 182 127   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0 127 170 168 175 211 191 163 184 113   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0  78 132 175 177 129 203 161 187 102   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0  91 166 163 190  63 203 159 189  94   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0  98 126 166 192  65 198 167 193  84   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0  90 127 170 198  61 200 174 198  71   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0  93 141 151 207  55 196 171 196  58   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0  88 137 136 210  54 198 173 199  46   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0  72 125 131 214  55 199 176 200  38   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0  56 146 126 210  56 200 175 200  37   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0  40 237 171 195  64 199 174 203  36   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0  23 190 168 192  70 196 171 203  30   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0  15 188 171 196  70 198 173 202  21   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0  11 187 172 197  71 199 174 203  15   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   1 183 175 198  73 195 174 205  13   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0 186 177 200  78 191 175 171   8   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0 181 177 198  78 189 176 166   4   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0 178 182 182 107 184 175 193   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0 173 200 206  84 196 196 133   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0  68 207 182   0 175 195  34   0   0   0   0   0   0   0   0   0   0]]\n",
            "1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BGLNT87GdK9C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_images = training_images / 255.0\n",
        "test_images = test_images / 255.0"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ko10sbphaH-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\n",
        "])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yHLebJUEiF1h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "e0a14539-e400-4739-fe52-9d301f603e8d"
      },
      "source": [
        "model.compile(optimizer= tf.optimizers.Adam(),\n",
        "              loss = tf.losses.sparse_categorical_crossentropy,\n",
        "              metrics = ['accuracy'])\n",
        "\n",
        "model.fit(training_images, training_labels, epochs=10)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.5001 - accuracy: 0.8232\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3737 - accuracy: 0.8649\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3357 - accuracy: 0.8779\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3114 - accuracy: 0.8844\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2942 - accuracy: 0.8915\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2780 - accuracy: 0.8967\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2667 - accuracy: 0.8997\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2560 - accuracy: 0.9054\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2476 - accuracy: 0.9088\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2388 - accuracy: 0.9122\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f4af33b5f60>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5CAcyHBWolLJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "9619777b-0154-4c79-f098-fec8128de9f9"
      },
      "source": [
        "model.evaluate(test_images,test_labels)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 0.3461 - accuracy: 0.8778\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.34609195590019226, 0.8777999877929688]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Ukb-SKVrppH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4bb5aae9-e535-4f75-e83a-e849eefd7b75"
      },
      "source": [
        "classifications = model.predict(test_images)\n",
        "print(classifications[0])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[3.8946695e-07 6.5738777e-12 1.6890555e-08 5.4544518e-11 2.1597408e-09 1.3836764e-04 1.6785313e-08 1.1879323e-03 1.4475310e-08 9.9867332e-01]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-XGoqSIdr5ef",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ea732055-2f9e-4ee1-fb0f-b15746b959f6"
      },
      "source": [
        "print(test_labels[0])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6gdsAE4oPP7n",
        "colab_type": "text"
      },
      "source": [
        "2. Experimenting with different values for datsets, dense layer etc"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GKZYeDJ4MOVk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f98d6986-74ca-4e73-f323-3b59137c8585"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ccl-5k51PewS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "a8fe959c-a612-47aa-f66f-1a3b0af32ceb"
      },
      "source": [
        "mnist = tf.keras.datasets.fashion_mnist\n",
        "(training_images,training_labels),(test_images,test_labels) = mnist.load_data()\n",
        "\n",
        "training_images = training_images / 255.0\n",
        "test_images = test_images / 255.0\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(1024, activation='relu'),\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer=tf.optimizers.Adam(),\n",
        "              loss=tf.losses.sparse_categorical_crossentropy,\n",
        "              metrics = ['accuracy'])\n",
        "              \n",
        "model.fit(training_images, training_labels, epochs=5)\n",
        "\n",
        "model.evaluate(test_images, test_labels)\n",
        "\n",
        "classifications = model.predict(test_images)\n",
        "\n",
        "print(classifications[0])\n",
        "print(test_labels[0])"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n",
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.4710 - accuracy: 0.8315\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3602 - accuracy: 0.8677\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3195 - accuracy: 0.8820\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2948 - accuracy: 0.8905\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2798 - accuracy: 0.8969\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.3271 - accuracy: 0.8828\n",
            "[2.4308022e-07 4.8010627e-08 7.3788534e-08 4.5010541e-08 9.9117106e-09\n",
            " 6.0143636e-04 2.9809710e-06 1.8020898e-02 2.6908927e-08 9.8137432e-01]\n",
            "9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sxm2wTUeBsD2",
        "colab_type": "text"
      },
      "source": [
        "3. Commenting the Flatten() layer and seeing the impact that it does."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fiHOOjt-VNbn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        },
        "outputId": "acd2a181-304f-45a5-c0b7-f7dd882b39c3"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "training_images = training_images / 255.0\n",
        "test_images = test_images / 255.0\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "                                    #tf.keras.layers.Flatten(),\n",
        "                                    tf.keras.layers.Dense(64, activation=tf.keras.activations.relu),\n",
        "                                    tf.keras.layers.Dense(10, activation=tf.keras.activations.softmax)\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss=tf.keras.losses.sparse_categorical_crossentropy)\n",
        "\n",
        "model.fit(training_images, training_labels, epochs=5)\n",
        "\n",
        "model.evaluate(test_images, test_labels)\n",
        "\n",
        "classifications = model.predict(test_images)\n",
        "\n",
        "print(classifications[0])\n",
        "#print(test_images[0])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.2.0\n",
            "Epoch 1/5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-43d439d135df>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse_categorical_crossentropy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m               \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m               \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    625\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 627\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    628\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    504\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    505\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 506\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    508\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2444\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2445\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2446\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2447\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2448\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2775\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2776\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2777\u001b[0;31m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2778\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2779\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   2665\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2666\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2667\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   2668\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2669\u001b[0m         \u001b[0;31m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    979\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 981\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    982\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    983\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    439\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    442\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    966\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 968\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    969\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:571 train_function  *\n        outputs = self.distribute_strategy.run(\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:951 run  **\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2290 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2649 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:533 train_step  **\n        y, y_pred, sample_weight, regularization_losses=self.losses)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/compile_utils.py:205 __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/losses.py:143 __call__\n        losses = self.call(y_true, y_pred)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/losses.py:246 call\n        return self.fn(y_true, y_pred, **self._fn_kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/losses.py:1558 sparse_categorical_crossentropy\n        y_true, y_pred, from_logits=from_logits, axis=axis)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py:4655 sparse_categorical_crossentropy\n        labels=target, logits=output)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_ops.py:3591 sparse_softmax_cross_entropy_with_logits_v2\n        labels=labels, logits=logits, name=name)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_ops.py:3507 sparse_softmax_cross_entropy_with_logits\n        logits.get_shape()))\n\n    ValueError: Shape mismatch: The shape of labels (received (32, 1)) should equal the shape of logits except for the last dimension (received (32, 28, 10)).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wz17doTjJEy6",
        "colab_type": "text"
      },
      "source": [
        "4. Why output layer has 10 classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YKqoo7npJIjE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c1074970-e1d9-455d-b049-96521e557329"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "training_images = training_images / 255.0\n",
        "test_images = test_images / 255.0\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "                                    tf.keras.layers.Flatten(),\n",
        "                                    tf.keras.layers.Dense(64, activation=tf.keras.activations.relu),\n",
        "                                    tf.keras.layers.Dense(5, activation=tf.keras.activations.softmax)\n",
        "])\n",
        "\n",
        "model.compile(optimizer = 'adam', loss=tf.keras.losses.sparse_categorical_crossentropy)\n",
        "\n",
        "model.fit(training_images, training_labels, epochs=5)\n",
        "\n",
        "model.evaluate(test_images, test_labels)\n",
        "\n",
        "classifications = model.predict(test_images)\n",
        "\n",
        "print(classifications[0])\n",
        "print(test_images[0])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.2.0\n",
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: nan\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: nan\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: nan\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: nan\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: nan\n",
            "313/313 [==============================] - 1s 2ms/step - loss: nan\n",
            "[nan nan nan nan nan]\n",
            "[[0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.32941176 0.7254902  0.62352941 0.59215686 0.23529412 0.14117647\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.87058824 0.99607843 0.99607843 0.99607843 0.99607843 0.94509804\n",
            "  0.77647059 0.77647059 0.77647059 0.77647059 0.77647059 0.77647059\n",
            "  0.77647059 0.77647059 0.66666667 0.20392157 0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.2627451  0.44705882 0.28235294 0.44705882 0.63921569 0.89019608\n",
            "  0.99607843 0.88235294 0.99607843 0.99607843 0.99607843 0.98039216\n",
            "  0.89803922 0.99607843 0.99607843 0.54901961 0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.06666667\n",
            "  0.25882353 0.05490196 0.2627451  0.2627451  0.2627451  0.23137255\n",
            "  0.08235294 0.9254902  0.99607843 0.41568627 0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.3254902  0.99215686 0.81960784 0.07058824 0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.08627451\n",
            "  0.91372549 1.         0.3254902  0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.50588235\n",
            "  0.99607843 0.93333333 0.17254902 0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.23137255 0.97647059\n",
            "  0.99607843 0.24313725 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.52156863 0.99607843\n",
            "  0.73333333 0.01960784 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.03529412 0.80392157 0.97254902\n",
            "  0.22745098 0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.49411765 0.99607843 0.71372549\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.29411765 0.98431373 0.94117647 0.22352941\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.0745098  0.86666667 0.99607843 0.65098039 0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.01176471 0.79607843 0.99607843 0.85882353 0.1372549  0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.14901961 0.99607843 0.99607843 0.30196078 0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.12156863\n",
            "  0.87843137 0.99607843 0.45098039 0.00392157 0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.52156863\n",
            "  0.99607843 0.99607843 0.20392157 0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.23921569 0.94901961\n",
            "  0.99607843 0.99607843 0.20392157 0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.4745098  0.99607843\n",
            "  0.99607843 0.85882353 0.15686275 0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.4745098  0.99607843\n",
            "  0.81176471 0.07058824 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Te3hzSgsO8GW",
        "colab_type": "text"
      },
      "source": [
        "5. Adding an extra layer to the network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sTvB8_3ePDcY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "9c81866c-932f-4fc6-f06c-f332cf371d34"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(training_images, training_labels),(test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "training_images = training_images / 255.0\n",
        "test_images = test_images / 255.0\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "                                    tf.keras.layers.Flatten(),\n",
        "                                    tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
        "                                    tf.keras.layers.Dense(256, activation=tf.nn.relu),\n",
        "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss=tf.keras.losses.sparse_categorical_crossentropy)\n",
        "\n",
        "model.fit(training_images, training_labels, epochs=5)\n",
        "\n",
        "model.evaluate(test_images, test_labels)\n",
        "\n",
        "classifications = model.predict(test_images)\n",
        "\n",
        "print(classifications[0])\n",
        "#print(test_images[0])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.2.0\n",
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1862\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0771\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0538\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0406\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0312\n",
            "313/313 [==============================] - 0s 1ms/step - loss: 0.0826\n",
            "[4.3547748e-12 3.1982410e-08 4.1831538e-09 5.6196118e-08 4.6672483e-10\n",
            " 8.6120006e-10 1.4797042e-14 9.9999976e-01 5.6779446e-11 9.1429897e-08]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "54tl0N7gaoOh",
        "colab_type": "text"
      },
      "source": [
        "6. Impact of increasing/decreasing epochs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OiBonewZavLg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "c1123c94-90f3-4dac-a0c9-3c1012c00179"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(training_images, training_labels),(test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "training_images = training_images / 255.0\n",
        "test_images = test_images / 255.0\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "                                    tf.keras.layers.Flatten(),\n",
        "                                    tf.keras.layers.Dense(256, activation=tf.nn.relu),\n",
        "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss=tf.keras.losses.sparse_categorical_crossentropy)\n",
        "\n",
        "model.fit(training_images, training_labels, epochs=5)\n",
        "\n",
        "model.evaluate(test_images, test_labels)\n",
        "\n",
        "classifications = model.predict(test_images)\n",
        "\n",
        "print(classifications[0])\n",
        "#print(test_images[0])"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.2.0\n",
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.2212\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0920\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0616\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0442\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0337\n",
            "313/313 [==============================] - 0s 1ms/step - loss: 0.0760\n",
            "[2.8940285e-08 3.9210519e-09 1.3175612e-06 1.7019815e-03 4.5796665e-12\n",
            " 4.9464393e-06 9.5483222e-12 9.9818498e-01 2.7065675e-05 7.9508653e-05]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-XC6J3QbgHJF",
        "colab_type": "text"
      },
      "source": [
        "7. Impact of not normalizing the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "voMD0Od1gTVM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "53488f47-2567-45a1-fec3-aa8ed096a0c2"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(training_images, training_labels),(test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "                                    tf.keras.layers.Flatten(),\n",
        "                                    tf.keras.layers.Dense(256, activation=tf.nn.relu),\n",
        "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "])\n",
        "\n",
        "model.compile(optimizer = 'adam', loss=tf.keras.losses.sparse_categorical_crossentropy)\n",
        "model.fit(training_images, training_labels, epochs=5)\n",
        "model.evaluate(test_images, test_labels)\n",
        "classifications = model.predict(test_images)\n",
        "\n",
        "print(classifications[0])\n",
        "print(test_images[0])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.2.0\n",
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 2.7646\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3617\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2806\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2533\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2365\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.2915\n",
            "[2.2635350e-24 2.0220761e-21 1.0199442e-12 4.0583856e-07 1.5216873e-20\n",
            " 4.9533497e-09 1.0039367e-37 9.9999964e-01 1.1025528e-17 4.2498508e-11]\n",
            "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0  84 185 159 151  60  36   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0 222 254 254 254 254 241 198 198 198 198 198 198\n",
            "  198 198 170  52   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0  67 114  72 114 163 227 254 225 254 254 254 250\n",
            "  229 254 254 140   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0  17  66  14  67  67  67  59\n",
            "   21 236 254 106   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   83 253 209  18   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  22\n",
            "  233 255  83   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 129\n",
            "  254 238  44   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  59 249\n",
            "  254  62   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 133 254\n",
            "  187   5   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   9 205 248\n",
            "   58   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 126 254 182\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  75 251 240  57\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0  19 221 254 166   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   3 203 254 219  35   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0  38 254 254  77   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0  31 224 254 115   1   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0 133 254 254  52   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0  61 242 254 254  52   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0 121 254 254 219  40   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0 121 254 207  18   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WuipI2zxnfpo",
        "colab_type": "text"
      },
      "source": [
        "Callbacks, to stop training when a desired value is reached"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0Mn2Iucj7aE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "da643e66-06c6-4794-b742-1120d500b8d9"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "from math import log\n",
        "\n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if(logs.get('loss')<0.4):\n",
        "      print(\"\\n Reached 60% accuracy. So cancelling the training!\")\n",
        "      self.model.stop_training = True\n",
        "\n",
        "callbacks = myCallback()\n",
        "mnist = tf.keras.datasets.fashion_mnist\n",
        "(training_images, training_labels),(test_images,test_labels) = mnist.load_data()\n",
        "training_images = training_images / 255.0\n",
        "test_images = test_images / 255.0\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "                                    tf.keras.layers.Flatten(),\n",
        "                                    tf.keras.layers.Dense(256, activation=tf.nn.relu),\n",
        "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss=tf.keras.losses.sparse_categorical_crossentropy)\n",
        "\n",
        "model.fit(training_images, training_labels, epochs=5, callbacks=[callbacks])\n",
        "\n",
        "model.evaluate(test_images, test_labels)\n",
        "\n",
        "classifications = model.predict(test_images)\n",
        "\n",
        "print(classifications[0])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.2.0\n",
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.4839\n",
            "Epoch 2/5\n",
            "1858/1875 [============================>.] - ETA: 0s - loss: 0.3629\n",
            " Reached 60% accuracy. So cancelling the training!\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3635\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.3735\n",
            "[2.0743075e-05 1.0547814e-06 3.3841377e-06 3.1637662e-06 2.1923215e-06\n",
            " 6.0522735e-02 3.1034492e-06 8.2492761e-02 8.3155883e-04 8.5611933e-01]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3HuQT0rrtrXG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}